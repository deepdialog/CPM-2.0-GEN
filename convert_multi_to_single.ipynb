{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把4个用于并行训练的模型文件，合并为一个单一的模型文件，让它可以更容易在CPU和单GPU上运行\n",
    "\n",
    "vocab.txt 的字典大小 = 26240\n",
    "词向量dim为4096\n",
    "\n",
    "word_embeds.weight 的总大小应该是 6560 * 4, 4096\n",
    "\n",
    "word_embeds.weight, encoder.word_embeds.weight, decoder.word_embeds.weight 这三者是同一个东西\n",
    "\n",
    "lm_head.weight 的总大小应该是 6560 * 4, 4096，它应该是最后生成生成的词向量\n",
    "\n",
    "encoder.blocks.0.ff.layer_norm.weight 这些东西4个文件里的都一样，存一个就好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvocab.txt 的字典大小 = 26240\\n词向量dim为4096\\n\\nword_embeds.weight 的总大小应该是 6560 * 4, 4096\\n\\nword_embeds.weight, encoder.word_embeds.weight, decoder.word_embeds.weight 这三者是同一个东西\\n\\nlm_head.weight 的总大小应该是 6560 * 4, 4096，它应该是最后生成生成的词向量\\n\\nencoder.blocks.0.ff.layer_norm.weight 这些东西4个文件里的都一样，存一个就好\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 0\n",
      "load 1\n",
      "load 2\n",
      "load 3\n",
      "loaded\n"
     ]
    }
   ],
   "source": [
    "print('load 0')\n",
    "m0 = torch.load('../100000/mp_rank_00_model_states.pt', map_location='cpu')\n",
    "print('load 1')\n",
    "m1 = torch.load('../100000/mp_rank_01_model_states.pt', map_location='cpu')\n",
    "print('load 2')\n",
    "m2 = torch.load('../100000/mp_rank_02_model_states.pt', map_location='cpu')\n",
    "print('load 3')\n",
    "m3 = torch.load('../100000/mp_rank_03_model_states.pt', map_location='cpu')\n",
    "print('loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_weight(model, name):\n",
    "    for n, w in model['module'].items():\n",
    "        if name == n:\n",
    "            return w, list(w.shape)\n",
    "\n",
    "def combine(n, dim=0):\n",
    "    return torch.cat([\n",
    "        find_weight(x, n)[0]\n",
    "        for x in (m0, m1, m2, m3)\n",
    "    ], dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_weight(m0, 'decoder.blocks.13.cross_attn.cross_attn.dense.weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state_dict = OrderedDict()\n",
    "\n",
    "for n, w in m0['module'].items():\n",
    "    if '.blocks.' in n:\n",
    "        if 'encoder' in n:\n",
    "            dim_0 = [\n",
    "                'ff.dense_relu_dense.wi_0.weight',\n",
    "                'ff.dense_relu_dense.wi_1.weight',\n",
    "            ]\n",
    "            dim_1 = [\n",
    "                'self_attn.self_attn.relative_attention_bias.weight',\n",
    "                'self_attn.self_attn.dense.weight',\n",
    "                'ff.dense_relu_dense.wo.weight'\n",
    "            ]\n",
    "            dim_no = [\n",
    "                'self_attn.layer_norm.weight',\n",
    "                'ff.layer_norm.weight'\n",
    "            ]\n",
    "            clean_name = re.sub(r'^\\d+', '', n[15:])[1:]\n",
    "            \n",
    "            if clean_name == 'self_attn.self_attn.project.weight':\n",
    "                t0 = find_weight(m0, n)[0]\n",
    "                t1 = find_weight(m1, n)[0]\n",
    "                t2 = find_weight(m2, n)[0]\n",
    "                t3 = find_weight(m3, n)[0]\n",
    "\n",
    "                a0 = t0[:1024, :]\n",
    "                b0 = t0[1024:2048, :]\n",
    "                c0 = t0[2048:, :]\n",
    "\n",
    "                a1 = t1[:1024, :]\n",
    "                b1 = t1[1024:2048, :]\n",
    "                c1 = t1[2048:, :]\n",
    "\n",
    "                a2 = t2[:1024, :]\n",
    "                b2 = t2[1024:2048, :]\n",
    "                c2 = t2[2048:, :]\n",
    "\n",
    "                a3 = t3[:1024, :]\n",
    "                b3 = t3[1024:2048, :]\n",
    "                c3 = t3[2048:, :]\n",
    "\n",
    "                new_state_dict[n] = torch.cat([\n",
    "                    a0, a1, a2, a3,\n",
    "                    b0, b1, b2, b3,\n",
    "                    c0, c1, c2, c3\n",
    "                ], dim=0)\n",
    "            elif clean_name in dim_0:\n",
    "                new_state_dict[n] = combine(n, dim=0)\n",
    "            elif clean_name in dim_1:\n",
    "                new_state_dict[n] = combine(n, dim=1)\n",
    "            elif clean_name in dim_no:\n",
    "                new_state_dict[n] = find_weight(m0, n)[0]\n",
    "            else:\n",
    "                raise Exception('encoder what?')\n",
    "        elif 'decoder' in n:\n",
    "            dim_0 = [\n",
    "                'cross_attn.cross_attn.project_q.weight',\n",
    "                'ff.dense_relu_dense.wi_0.weight',\n",
    "                'ff.dense_relu_dense.wi_1.weight',\n",
    "            ]\n",
    "            dim_1 = [\n",
    "                'self_attn.self_attn.dense.weight',\n",
    "                'self_attn.self_attn.relative_attention_bias.weight',\n",
    "                'cross_attn.cross_attn.dense.weight',\n",
    "                'ff.dense_relu_dense.wo.weight',\n",
    "            ]\n",
    "            dim_no = [\n",
    "                'self_attn.layer_norm.weight',\n",
    "                'cross_attn.layer_norm.weight',\n",
    "                'ff.layer_norm.weight'\n",
    "            ]\n",
    "            clean_name = re.sub(r'^\\d+', '', n[15:])[1:]\n",
    "\n",
    "            if clean_name == 'self_attn.self_attn.project.weight':\n",
    "\n",
    "                t0 = find_weight(m0, n)[0]\n",
    "                t1 = find_weight(m1, n)[0]\n",
    "                t2 = find_weight(m2, n)[0]\n",
    "                t3 = find_weight(m3, n)[0]\n",
    "\n",
    "                a0 = t0[:1024, :]\n",
    "                b0 = t0[1024:2048, :]\n",
    "                c0 = t0[2048:, :]\n",
    "\n",
    "                a1 = t1[:1024, :]\n",
    "                b1 = t1[1024:2048, :]\n",
    "                c1 = t1[2048:, :]\n",
    "\n",
    "                a2 = t2[:1024, :]\n",
    "                b2 = t2[1024:2048, :]\n",
    "                c2 = t2[2048:, :]\n",
    "\n",
    "                a3 = t3[:1024, :]\n",
    "                b3 = t3[1024:2048, :]\n",
    "                c3 = t3[2048:, :]\n",
    "\n",
    "                new_state_dict[n] = torch.cat([\n",
    "                    a0, a1, a2, a3,\n",
    "                    b0, b1, b2, b3,\n",
    "                    c0, c1, c2, c3\n",
    "                ], dim=0)\n",
    "            elif clean_name == 'cross_attn.cross_attn.project_kv.weight':\n",
    "                t0 = find_weight(m0, n)[0]\n",
    "                t1 = find_weight(m1, n)[0]\n",
    "                t2 = find_weight(m2, n)[0]\n",
    "                t3 = find_weight(m3, n)[0]\n",
    "\n",
    "                a0 = t0[:1024, :]\n",
    "                b0 = t0[1024:, :]\n",
    "\n",
    "                a1 = t1[:1024, :]\n",
    "                b1 = t1[1024:, :]\n",
    "\n",
    "                a2 = t2[:1024, :]\n",
    "                b2 = t2[1024:, :]\n",
    "\n",
    "                a3 = t3[:1024, :]\n",
    "                b3 = t3[1024:, :]\n",
    "\n",
    "                new_state_dict[n] = torch.cat([\n",
    "                    a0, a1, a2, a3,\n",
    "                    b0, b1, b2, b3,\n",
    "                ])\n",
    "            elif clean_name in dim_0:\n",
    "                new_state_dict[n] = combine(n, dim=0)\n",
    "            elif clean_name in dim_1:\n",
    "                new_state_dict[n] = combine(n, dim=1)\n",
    "            elif clean_name in dim_no:\n",
    "                new_state_dict[n] = find_weight(m0, n)[0]\n",
    "            else:\n",
    "                raise Exception('decoder what?')\n",
    "    else:\n",
    "        dim_0 = [\n",
    "            'word_embeds.weight',\n",
    "            'lm_head.weight',\n",
    "            'encoder.word_embeds.weight',\n",
    "            'decoder.word_embeds.weight',\n",
    "        ]\n",
    "        dim_1 = [\n",
    "        ]\n",
    "        dim_no = [\n",
    "            'encoder.final_layernorm.weight',\n",
    "            'decoder.final_layernorm.weight',\n",
    "        ]\n",
    "        if n in dim_0:\n",
    "            new_state_dict[n] = combine(n, dim=0)\n",
    "        elif n in dim_1:\n",
    "            new_state_dict[n] = combine(n, dim=1)\n",
    "        elif n in dim_no:\n",
    "            new_state_dict[n] = find_weight(m0, n)[0]\n",
    "        else:\n",
    "            raise Exception('other what?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(new_state_dict, 'converted.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan 1000  43G Aug 24 01:01 converted_32.state_dict\r\n",
      "-rw-r--r-- 1 jovyan 1000  22G Aug 23 22:44 converted.state_dict\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh . | grep converted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
