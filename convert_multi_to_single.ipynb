{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把4个用于并行训练的模型文件，合并为一个单一的模型文件，让它可以更容易在CPU和单GPU上运行\n",
    "\n",
    "vocab.txt 的字典大小 = 26240\n",
    "词向量dim为4096\n",
    "\n",
    "word_embeds.weight 的总大小应该是 6560 * 4, 4096\n",
    "\n",
    "word_embeds.weight, encoder.word_embeds.weight, decoder.word_embeds.weight 这三者是同一个东西\n",
    "\n",
    "lm_head.weight 的总大小应该是 6560 * 4, 4096，它应该是最后生成生成的词向量\n",
    "\n",
    "encoder.blocks.0.ff.layer_norm.weight 这些东西4个文件里的都一样，存一个就好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../32000/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 0\n",
      "load 1\n",
      "load 2\n",
      "load 3\n",
      "loaded\n"
     ]
    }
   ],
   "source": [
    "print('load 0')\n",
    "m0 = torch.load(root + 'mp_rank_00_model_states.pt', map_location='cpu')\n",
    "print('load 1')\n",
    "m1 = torch.load(root + 'mp_rank_01_model_states.pt', map_location='cpu')\n",
    "print('load 2')\n",
    "m2 = torch.load(root + 'mp_rank_02_model_states.pt', map_location='cpu')\n",
    "print('load 3')\n",
    "m3 = torch.load(root + 'mp_rank_03_model_states.pt', map_location='cpu')\n",
    "print('loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_weight(model, name):\n",
    "    for n, w in model['module'].items():\n",
    "        if name == n:\n",
    "            return w, list(w.shape)\n",
    "\n",
    "def combine(n, dim=0):\n",
    "    return torch.cat([\n",
    "        find_weight(x, n)[0]\n",
    "        for x in (m0, m1, m2, m3)\n",
    "    ], dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_weight(m0, 'decoder.blocks.13.cross_attn.cross_attn.dense.weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state_dict = OrderedDict()\n",
    "\n",
    "for n, w in m0['module'].items():\n",
    "    if '.blocks.' in n:\n",
    "        if 'encoder' in n:\n",
    "            dim_0 = [\n",
    "                'ff.dense_relu_dense.wi_0.weight',\n",
    "                'ff.dense_relu_dense.wi_1.weight',\n",
    "            ]\n",
    "            dim_1 = [\n",
    "                'self_attn.self_attn.relative_attention_bias.weight',\n",
    "                'self_attn.self_attn.dense.weight',\n",
    "                'ff.dense_relu_dense.wo.weight'\n",
    "            ]\n",
    "            dim_no = [\n",
    "                'self_attn.layer_norm.weight',\n",
    "                'ff.layer_norm.weight'\n",
    "            ]\n",
    "            clean_name = re.sub(r'^\\d+', '', n[15:])[1:]\n",
    "            \n",
    "            if clean_name == 'self_attn.self_attn.project.weight':\n",
    "                t0 = find_weight(m0, n)[0]\n",
    "                t1 = find_weight(m1, n)[0]\n",
    "                t2 = find_weight(m2, n)[0]\n",
    "                t3 = find_weight(m3, n)[0]\n",
    "\n",
    "                a0 = t0[:1024, :]\n",
    "                b0 = t0[1024:2048, :]\n",
    "                c0 = t0[2048:, :]\n",
    "\n",
    "                a1 = t1[:1024, :]\n",
    "                b1 = t1[1024:2048, :]\n",
    "                c1 = t1[2048:, :]\n",
    "\n",
    "                a2 = t2[:1024, :]\n",
    "                b2 = t2[1024:2048, :]\n",
    "                c2 = t2[2048:, :]\n",
    "\n",
    "                a3 = t3[:1024, :]\n",
    "                b3 = t3[1024:2048, :]\n",
    "                c3 = t3[2048:, :]\n",
    "\n",
    "                new_state_dict[n] = torch.cat([\n",
    "                    a0, a1, a2, a3,\n",
    "                    b0, b1, b2, b3,\n",
    "                    c0, c1, c2, c3\n",
    "                ], dim=0)\n",
    "            elif clean_name in dim_0:\n",
    "                new_state_dict[n] = combine(n, dim=0)\n",
    "            elif clean_name in dim_1:\n",
    "                new_state_dict[n] = combine(n, dim=1)\n",
    "            elif clean_name in dim_no:\n",
    "                new_state_dict[n] = find_weight(m0, n)[0]\n",
    "            else:\n",
    "                raise Exception('encoder what?')\n",
    "        elif 'decoder' in n:\n",
    "            dim_0 = [\n",
    "                'cross_attn.cross_attn.project_q.weight',\n",
    "                'ff.dense_relu_dense.wi_0.weight',\n",
    "                'ff.dense_relu_dense.wi_1.weight',\n",
    "            ]\n",
    "            dim_1 = [\n",
    "                'self_attn.self_attn.dense.weight',\n",
    "                'self_attn.self_attn.relative_attention_bias.weight',\n",
    "                'cross_attn.cross_attn.dense.weight',\n",
    "                'ff.dense_relu_dense.wo.weight',\n",
    "            ]\n",
    "            dim_no = [\n",
    "                'self_attn.layer_norm.weight',\n",
    "                'cross_attn.layer_norm.weight',\n",
    "                'ff.layer_norm.weight'\n",
    "            ]\n",
    "            clean_name = re.sub(r'^\\d+', '', n[15:])[1:]\n",
    "\n",
    "            if clean_name == 'self_attn.self_attn.project.weight':\n",
    "\n",
    "                t0 = find_weight(m0, n)[0]\n",
    "                t1 = find_weight(m1, n)[0]\n",
    "                t2 = find_weight(m2, n)[0]\n",
    "                t3 = find_weight(m3, n)[0]\n",
    "\n",
    "                a0 = t0[:1024, :]\n",
    "                b0 = t0[1024:2048, :]\n",
    "                c0 = t0[2048:, :]\n",
    "\n",
    "                a1 = t1[:1024, :]\n",
    "                b1 = t1[1024:2048, :]\n",
    "                c1 = t1[2048:, :]\n",
    "\n",
    "                a2 = t2[:1024, :]\n",
    "                b2 = t2[1024:2048, :]\n",
    "                c2 = t2[2048:, :]\n",
    "\n",
    "                a3 = t3[:1024, :]\n",
    "                b3 = t3[1024:2048, :]\n",
    "                c3 = t3[2048:, :]\n",
    "\n",
    "                new_state_dict[n] = torch.cat([\n",
    "                    a0, a1, a2, a3,\n",
    "                    b0, b1, b2, b3,\n",
    "                    c0, c1, c2, c3\n",
    "                ], dim=0)\n",
    "            elif clean_name == 'cross_attn.cross_attn.project_kv.weight':\n",
    "                t0 = find_weight(m0, n)[0]\n",
    "                t1 = find_weight(m1, n)[0]\n",
    "                t2 = find_weight(m2, n)[0]\n",
    "                t3 = find_weight(m3, n)[0]\n",
    "\n",
    "                a0 = t0[:1024, :]\n",
    "                b0 = t0[1024:, :]\n",
    "\n",
    "                a1 = t1[:1024, :]\n",
    "                b1 = t1[1024:, :]\n",
    "\n",
    "                a2 = t2[:1024, :]\n",
    "                b2 = t2[1024:, :]\n",
    "\n",
    "                a3 = t3[:1024, :]\n",
    "                b3 = t3[1024:, :]\n",
    "\n",
    "                new_state_dict[n] = torch.cat([\n",
    "                    a0, a1, a2, a3,\n",
    "                    b0, b1, b2, b3,\n",
    "                ])\n",
    "            elif clean_name in dim_0:\n",
    "                new_state_dict[n] = combine(n, dim=0)\n",
    "            elif clean_name in dim_1:\n",
    "                new_state_dict[n] = combine(n, dim=1)\n",
    "            elif clean_name in dim_no:\n",
    "                new_state_dict[n] = find_weight(m0, n)[0]\n",
    "            else:\n",
    "                raise Exception('decoder what?')\n",
    "    else:\n",
    "        dim_0 = [\n",
    "            'word_embeds.weight',\n",
    "            'lm_head.weight',\n",
    "            'encoder.word_embeds.weight',\n",
    "            'decoder.word_embeds.weight',\n",
    "        ]\n",
    "        dim_1 = [\n",
    "        ]\n",
    "        dim_no = [\n",
    "            'encoder.final_layernorm.weight',\n",
    "            'decoder.final_layernorm.weight',\n",
    "        ]\n",
    "        if n in dim_0:\n",
    "            new_state_dict[n] = combine(n, dim=0)\n",
    "        elif n in dim_1:\n",
    "            new_state_dict[n] = combine(n, dim=1)\n",
    "        elif n in dim_no:\n",
    "            new_state_dict[n] = find_weight(m0, n)[0]\n",
    "        else:\n",
    "            raise Exception('other what?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_embeds.weight torch.Size([51968, 4096])\n",
      "lm_head.weight torch.Size([51968, 4096])\n",
      "encoder.word_embeds.weight torch.Size([51968, 4096])\n",
      "encoder.final_layernorm.weight torch.Size([4096])\n",
      "encoder.blocks.0.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.0.self_attn.self_attn.relative_attention_bias.weight torch.Size([32, 64])\n",
      "encoder.blocks.0.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.0.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.0.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.0.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.0.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.0.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.1.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.1.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.1.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.1.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.1.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.1.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.1.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.2.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.2.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.2.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.2.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.2.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.2.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.2.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.3.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.3.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.3.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.3.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.3.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.3.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.3.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.4.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.4.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.4.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.4.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.4.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.4.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.4.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.5.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.5.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.5.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.5.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.5.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.5.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.5.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.6.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.6.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.6.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.6.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.6.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.6.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.6.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.7.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.7.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.7.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.7.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.7.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.7.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.7.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.8.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.8.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.8.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.8.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.8.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.8.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.8.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.9.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.9.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.9.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.9.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.9.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.9.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.9.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.10.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.10.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.10.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.10.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.10.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.10.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.10.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.11.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.11.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.11.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.11.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.11.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.11.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.11.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.12.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.12.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.12.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.12.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.12.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.12.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.12.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.13.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.13.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.13.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.13.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.13.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.13.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.13.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.14.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.14.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.14.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.14.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.14.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.14.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.14.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.15.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.15.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.15.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.15.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.15.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.15.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.15.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.16.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.16.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.16.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.16.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.16.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.16.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.16.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.17.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.17.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.17.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.17.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.17.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.17.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.17.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.18.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.18.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.18.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.18.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.18.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.18.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.18.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.19.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.19.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.19.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.19.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.19.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.19.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.19.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.20.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.20.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.20.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.20.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.20.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.20.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.20.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.21.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.21.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.21.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.21.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.21.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.21.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.21.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.22.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.22.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.22.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.22.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.22.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.22.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.22.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.23.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.23.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.23.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.23.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.23.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.23.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.23.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.word_embeds.weight torch.Size([51968, 4096])\n",
      "decoder.final_layernorm.weight torch.Size([4096])\n",
      "decoder.blocks.0.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.0.self_attn.self_attn.relative_attention_bias.weight torch.Size([32, 64])\n",
      "decoder.blocks.0.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.0.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.0.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.0.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.0.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.0.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.0.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.0.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.0.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.0.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.1.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.1.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.1.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.1.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.1.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.1.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.1.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.1.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.1.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.1.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.1.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.2.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.2.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.2.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.2.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.2.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.2.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.2.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.2.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.2.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.2.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.2.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.3.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.3.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.3.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.3.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.3.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.3.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.3.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.3.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.3.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.3.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.3.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.4.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.4.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.4.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.4.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.4.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.4.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.4.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.4.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.4.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.4.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.4.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.5.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.5.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.5.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.5.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.5.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.5.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.5.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.5.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.5.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.5.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.5.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.6.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.6.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.6.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.6.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.6.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.6.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.6.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.6.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.6.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.6.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.6.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.7.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.7.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.7.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.7.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.7.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.7.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.7.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.7.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.7.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.7.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.7.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.8.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.8.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.8.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.8.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.8.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.8.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.8.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.8.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.8.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.8.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.8.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.9.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.9.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.9.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.9.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.9.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.9.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.9.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.9.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.9.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.9.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.9.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.10.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.10.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.10.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.10.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.10.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.10.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.10.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.10.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.10.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.10.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.10.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.11.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.11.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.11.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.11.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.11.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.11.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.11.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.11.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.11.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.11.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.11.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.12.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.12.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.12.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.12.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.12.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.12.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.12.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.12.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.12.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.12.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.12.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.13.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.13.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.13.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.13.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.13.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.13.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.13.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.13.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.13.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.13.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.13.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.14.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.14.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.14.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.14.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.14.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.14.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.14.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.14.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.14.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.14.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.14.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.15.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.15.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.15.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.15.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.15.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.15.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.15.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.15.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.15.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.15.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.15.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.16.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.16.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.16.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.16.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.16.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.16.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.16.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.16.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.16.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.16.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.16.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.17.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.17.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.17.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.17.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.17.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.17.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.17.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.17.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.17.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.17.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.17.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.18.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.18.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.18.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.18.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.18.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.18.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.18.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.18.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.18.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.18.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.18.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.19.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.19.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.19.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.19.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.19.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.19.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.19.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.19.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.19.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.19.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.19.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.20.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.20.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.20.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.20.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.20.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.20.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.20.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.20.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.20.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.20.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.20.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.21.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.21.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.21.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.21.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.21.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.21.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.21.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.21.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.21.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.21.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.21.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.22.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.22.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.22.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.22.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.22.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.22.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.22.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.22.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.22.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.22.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.22.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.23.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.23.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.23.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.23.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.23.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.23.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.23.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.23.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.23.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.23.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.23.ff.layer_norm.weight torch.Size([4096])\n"
     ]
    }
   ],
   "source": [
    "for k, v in new_state_dict.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(new_state_dict, '../converted.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lh . | grep converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
