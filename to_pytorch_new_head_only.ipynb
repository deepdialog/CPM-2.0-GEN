{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import T5EncoderModel\n",
    "from transformers import T5Config\n",
    "\n",
    "from tokenization_enc_dec import EncDecTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = EncDecTokenizer('../zhiyuan/cpm2.1/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = T5Config(\n",
    "    vocab_size=26240,\n",
    "#     n_positions=self.n_positions,\n",
    "    d_model=4096,\n",
    "    d_ff=10240,\n",
    "    d_kv=4096 // 64,\n",
    "    num_layers=24,\n",
    "    num_heads=64,\n",
    "    relative_attention_num_buckets=32,\n",
    "    dropout_rate=0.0,\n",
    "    initializer_factor=1.0,\n",
    "    eos_token_id=tokenizer.eod_id,\n",
    "    bos_token_id=tokenizer.pad_id,\n",
    "    pad_token_id=tokenizer.pad_id,\n",
    "    decoder_start_token_id=tokenizer.pad_id,\n",
    "    feed_forward_proj='gated-gelu',\n",
    "    tie_word_embeddings=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5EncoderModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(input_ids=torch.LongTensor([[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def load_dtype(fp):\n",
    "    v = struct.unpack(\"B\", fp.read(1))[0]\n",
    "    if v == 0:\n",
    "        return np.int8\n",
    "    elif v == 1:\n",
    "        return np.float16\n",
    "    elif v == 2:\n",
    "        return np.float32\n",
    "    else:\n",
    "        raise TypeError(\"Unknown dtype %d\" % v)\n",
    "\n",
    "def load_string(fp):\n",
    "    size = struct.unpack(\"I\", fp.read(4))[0]\n",
    "    v = fp.read(size)\n",
    "    return v.decode(\"utf-8\")\n",
    "\n",
    "def load_tuple(fp):\n",
    "    dim_tuple = struct.unpack(\"B\", fp.read(1))[0]\n",
    "    ret = []\n",
    "    for _ in range(dim_tuple):\n",
    "        ret.append(struct.unpack(\"I\", fp.read(4))[0]) \n",
    "    return tuple(ret)\n",
    "\n",
    "def load_parameter(fp):    \n",
    "    shape = load_tuple(fp)\n",
    "    value_size = struct.unpack(\"I\", fp.read(4))[0]\n",
    "    dtype = load_dtype(fp)\n",
    "    value = fp.read(value_size)\n",
    "    return shape, value, dtype\n",
    "\n",
    "def load(fp, parent_name=''):\n",
    "    num_parameters, num_sub_layers = struct.unpack(\"II\", fp.read(8))\n",
    "    parameters = []\n",
    "\n",
    "    for _ in range(num_parameters):\n",
    "        name = load_string(fp)\n",
    "        shape, value, dtype = load_parameter(fp)\n",
    "        parameters.append((parent_name + '.' + name, np.frombuffer(value, dtype).reshape(shape)))\n",
    "    for _ in range(num_sub_layers):\n",
    "        name = load_string(fp)\n",
    "        parameters += load(fp, parent_name + '.' + name)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../zhiyuan/cpm2.1/checkpoint.pt', 'rb') as fp:\n",
    "    parameters = load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pindex = {x[0]: x[1] for x in parameters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 704/704 [03:05<00:00,  3.79it/s]\n"
     ]
    }
   ],
   "source": [
    "npara = {}\n",
    "for name, value in tqdm(parameters):\n",
    "    if '_scale' not in name:\n",
    "        has_scale = name + '_scale'\n",
    "        if has_scale in pindex:\n",
    "            scale = pindex[has_scale]\n",
    "            value = value.astype(np.float16) * scale\n",
    "        npara[name] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder(n):\n",
    "    params = []\n",
    "    for k, v in npara.items():\n",
    "        if n == 0 and '.encoder_position_bias.embedding.weight' in k:\n",
    "            params.append((\n",
    "                'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight',\n",
    "                v,\n",
    "            ))\n",
    "        if f'.encoder.{n}.' in k:\n",
    "            if 'self_attention.w_project_qkv' in k:\n",
    "                params.append((\n",
    "                    f'encoder.block.{n}.layer.0.SelfAttention.q.weight',\n",
    "                    v[0]\n",
    "                ))\n",
    "                params.append((\n",
    "                    f'encoder.block.{n}.layer.0.SelfAttention.k.weight',\n",
    "                    v[1]\n",
    "                ))\n",
    "                params.append((\n",
    "                    f'encoder.block.{n}.layer.0.SelfAttention.v.weight',\n",
    "                    v[2]\n",
    "                ))\n",
    "            if 'self_attention.w_out' in k:\n",
    "                params.append((\n",
    "                    f'encoder.block.{n}.layer.0.SelfAttention.o.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'layer_nrom_before_self_attn.weight' in k:\n",
    "                params.append((\n",
    "                    f'encoder.block.{n}.layer.0.layer_norm.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'dense_gelu_dense.wi_0.weight' in k:\n",
    "                params.append((\n",
    "                    f'encoder.block.{n}.layer.1.DenseReluDense.wi_0.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'dense_gelu_dense.wi_1.weight' in k:\n",
    "                params.append((\n",
    "                    f'encoder.block.{n}.layer.1.DenseReluDense.wi_1.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'dense_gelu_dense.wo.weight' in k:\n",
    "                params.append((\n",
    "                    f'encoder.block.{n}.layer.1.DenseReluDense.wo.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'layer_nrom_before_ff.weight' in k:\n",
    "                params.append((\n",
    "                    f'encoder.block.{n}.layer.1.layer_norm.weight',\n",
    "                    v,\n",
    "                ))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoder(n):\n",
    "    params = []\n",
    "    for k, v in npara.items():\n",
    "        if n == 0 and '.decoder_position_bias.embedding.weight' in k:\n",
    "            params.append((\n",
    "                'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight',\n",
    "                v,\n",
    "            ))\n",
    "        if f'.decoder.{n}.' in k:\n",
    "            if 'self_attention.w_project_qkv' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.0.SelfAttention.q.weight',\n",
    "                    v[0]\n",
    "                ))\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.0.SelfAttention.k.weight',\n",
    "                    v[1]\n",
    "                ))\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.0.SelfAttention.v.weight',\n",
    "                    v[2]\n",
    "                ))\n",
    "            if 'self_attention.w_out' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.0.SelfAttention.o.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'layer_nrom_before_self_attn.weight' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.0.layer_norm.weight',\n",
    "                    v,\n",
    "                ))\n",
    "                \n",
    "            if '.cross_attention.w_project_q' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.1.EncDecAttention.q.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if '.cross_attention.w_out' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.1.EncDecAttention.o.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'layer_nrom_before_cross_attn.weight' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.1.layer_norm.weight',\n",
    "                    v,\n",
    "                ))\n",
    "\n",
    "            if 'dense_gelu_dense.wi_0.weight' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.2.DenseReluDense.wi_0.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'dense_gelu_dense.wi_1.weight' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.2.DenseReluDense.wi_1.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'dense_gelu_dense.wo.weight' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.2.DenseReluDense.wo.weight',\n",
    "                    v,\n",
    "                ))\n",
    "            if 'layer_nrom_before_ff.weight' in k:\n",
    "                params.append((\n",
    "                    f'decoder.block.{n}.layer.2.layer_norm.weight',\n",
    "                    v,\n",
    "                ))\n",
    "#     params.append((\n",
    "#         f'decoder.block.{n}.layer.1.EncDecAttention.k.weight',\n",
    "#         npara[f'.encoder.{n}.self_attention.w_project_qkv'][1]\n",
    "#     ))\n",
    "#     params.append((\n",
    "#         f'decoder.block.{n}.layer.1.EncDecAttention.v.weight',\n",
    "#         npara[f'.encoder.{n}.self_attention.w_project_qkv'][2]\n",
    "#     ))\n",
    "    params.append((\n",
    "        f'decoder.block.{n}.layer.1.EncDecAttention.k.weight',\n",
    "        npara['.encoder_kv.w_project_kv'][n][0]\n",
    "    ))\n",
    "    params.append((\n",
    "        f'decoder.block.{n}.layer.1.EncDecAttention.v.weight',\n",
    "        npara['.encoder_kv.w_project_kv'][n][1]\n",
    "    ))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state_dict = []\n",
    "new_state_dict.append((\n",
    "    'shared.weight',\n",
    "    npara['.input_embedding.weight'],\n",
    "))\n",
    "new_state_dict.append((\n",
    "    'encoder.embed_tokens.weight',\n",
    "    npara['.input_embedding.weight'],\n",
    "))\n",
    "\n",
    "for i in range(24):\n",
    "    new_state_dict += get_encoder(i)\n",
    "\n",
    "new_state_dict.append((\n",
    "    'encoder.final_layer_norm.weight',\n",
    "    npara['.encoder_final_layer_nrom.weight'],\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-06207c3a9908>:2: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  k: torch.from_numpy(v)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict({\n",
    "    k: torch.from_numpy(v)\n",
    "    for k, v in new_state_dict\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.525 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "input_text = '''当地时间9月6日是美国劳工节，但就在这一天，上千万美国劳动者却陷入新的困境。因为美国政府为疫情期间失业者提供的主要救助同日到期，而且白宫表示没有进一步延长救助的计划。\n",
    "在德尔塔变异株已把美国推入新一轮疫情的背景下，失业救济的突然“断供”意味着有上千万美国人将全部或部分失去他们的生活来源。'''\n",
    "output_text = '''美国'''\n",
    "input_ids = torch.LongTensor([tokenizer.encode(input_text)])\n",
    "outs = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict, 'cpm-2.1-encoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.9G\tcpm-2.1-encoder.pt\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh 'cpm-2.1-encoder.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
