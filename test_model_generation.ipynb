{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, List\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import jieba\n",
    "from tqdm import tqdm\n",
    "\n",
    "from configuration_enc_dec import EncDecConfig\n",
    "from tokenization_enc_dec import EncDecTokenizer\n",
    "from model import TorchEncDecModel, top_k_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.564 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# !pip install jieba --user\n",
    "jieba.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26240"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = EncDecConfig(\n",
    "    d_model=4096,\n",
    "    d_ff=10240,\n",
    "    d_kv=64,\n",
    "    num_heads=64,\n",
    "    num_layers=24,\n",
    "    num_decoder_layers=24,\n",
    "    dropout_rate=0.0,\n",
    "    feed_forward_proj=\"relu\",\n",
    "    init_method_std=0.001,\n",
    "    initializer_factor=1.0,\n",
    "    layer_norm_epsilon=1e-06,\n",
    "    max_position_embeddings=512,\n",
    "    use_cache=True,\n",
    "    use_scaled_init_for_output_weights=True,\n",
    "    do_dim_trick=False\n",
    ")\n",
    "config.vocab_size = 26240\n",
    "config.vocab_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build model\n"
     ]
    }
   ],
   "source": [
    "print('build model')\n",
    "model = TorchEncDecModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To float16 and GPU\n",
    "if torch.cuda.is_available():\n",
    "    model = model.half().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load state\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('load state')\n",
    "model.load_state_dict(torch.load('converted.zip'))\n",
    "# model.load_state_dict(state_dict_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to eval\n"
     ]
    }
   ],
   "source": [
    "print('to eval')\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = EncDecTokenizer('./vocab.txt')\n",
    "\n",
    "\n",
    "def get_enc_hidden_state(input_prompt, dtype):\n",
    "    inputs = tokenizer.encode(input_prompt)\n",
    "    enc_input_ids = torch.tensor([\n",
    "        inputs\n",
    "    ], dtype=torch.long)\n",
    "    inputs_len = enc_input_ids.shape[1]\n",
    "    enc_attention_mask = torch.ones(1, 1, inputs_len, inputs_len, dtype=dtype)\n",
    "    if torch.cuda.is_available():\n",
    "        enc_input_ids = enc_input_ids.cuda()\n",
    "        enc_attention_mask = enc_attention_mask.cuda()\n",
    "    enc_outputs = model(enc_input_ids, only_encoder=True, enc_attention_mask=enc_attention_mask)\n",
    "    del enc_input_ids\n",
    "    del enc_attention_mask\n",
    "    enc_hidden_states = enc_outputs['encoder_last_hidden_state']\n",
    "    del enc_outputs\n",
    "    return inputs_len, enc_hidden_states\n",
    "\n",
    "\n",
    "def predict(input_prompt, output_prompt, length=100):\n",
    "    \n",
    "    dtype = torch.float32\n",
    "    if torch.cuda.is_available():\n",
    "        dtype = torch.float16\n",
    "\n",
    "    inputs_len, enc_hidden_states = get_enc_hidden_state(input_prompt, dtype)\n",
    "    outputs = [1, tokenizer.get_sentinel_id(0)] + tokenizer.encode(output_prompt)\n",
    "    past_key_values = None\n",
    "    raw_outputs_len = len(outputs)\n",
    "    out_texts = ''\n",
    "\n",
    "    for i in tqdm(range(length - raw_outputs_len)):\n",
    "\n",
    "        dec_input_ids = torch.tensor([\n",
    "            outputs\n",
    "        ], dtype=torch.long)\n",
    "\n",
    "        outputs_len = i + raw_outputs_len\n",
    "        if i == 0:\n",
    "            outputs_len = len(outputs)\n",
    "\n",
    "        cross_attention_mask = torch.zeros(1, 1, outputs_len, inputs_len, dtype=dtype)\n",
    "        cross_attention_mask[0, 0, :outputs_len, :inputs_len] = 1.0\n",
    "\n",
    "        dec_attention_mask = torch.zeros(1, 1, outputs_len, outputs_len, dtype=dtype)\n",
    "        dec_attention_mask[0][0] = torch.tril(torch.ones(outputs_len, outputs_len))\n",
    "\n",
    "        if i > 0:\n",
    "            cross_attention_mask = cross_attention_mask[:, :, -1:, :]\n",
    "            dec_attention_mask = dec_attention_mask[:, :, -1:, :]\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            dec_input_ids = dec_input_ids.cuda()\n",
    "            dec_attention_mask = dec_attention_mask.cuda()\n",
    "            cross_attention_mask = cross_attention_mask.cuda()\n",
    "\n",
    "        out = model(\n",
    "            dec_input_ids=dec_input_ids,\n",
    "            dec_attention_mask=dec_attention_mask,\n",
    "            cross_attention_mask=cross_attention_mask,\n",
    "            enc_hidden_states=enc_hidden_states,\n",
    "            past_key_values=past_key_values\n",
    "        )\n",
    "        \n",
    "        del dec_input_ids\n",
    "        del dec_attention_mask\n",
    "        del cross_attention_mask\n",
    "        del past_key_values\n",
    "        past_key_values = out['past_key_values']\n",
    "\n",
    "        temperature = 1.0\n",
    "        logits = out['lm_logits'][:, -1, :].detach().cpu().to(torch.float32)\n",
    "        logits[:, 0] = -10000\n",
    "        logits[:, 26050:] = -10000\n",
    "        del out\n",
    "\n",
    "        next_token_logscores = top_k_logits(logits / temperature, top_k=10, top_p=0.9)\n",
    "        probs = F.softmax(next_token_logscores, dim=-1)\n",
    "        next_token = torch.multinomial(probs.float(), num_samples=1).squeeze(1)\n",
    "        next_token_list = next_token.detach().cpu().numpy().tolist()\n",
    "\n",
    "        outputs = next_token_list\n",
    "        out_text = tokenizer.decode(outputs)\n",
    "        out_texts += out_text\n",
    "\n",
    "    del enc_hidden_states\n",
    "    return out_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt = '''外国人犯罪案件归基层检察机关管辖吗？\n",
    "根据中华人民共和国法律，基层检察机关可以办理外国人犯罪案件，涉外因素不是影响管辖的法定事由。\n",
    "《<中华人民共和国刑事诉讼法>解释》第393条：第一审涉外刑事案件，除刑事诉讼法第二十条至第二十二条规定的以外，由基层人民法院管辖。必要时，中级人民法院可以指定辖区内若干基层人民法院集中管辖第一审涉外刑事案件，也可以依照刑事诉讼法第二十三条的规定，审理基层人民法院管辖的第一审涉外刑事案件。\n",
    "人民检察院管辖范围与同级人民法院一致。\n",
    "外国人犯罪在犯罪构成、罪名和刑期方面与我国公民犯罪有什么区别吗？\n",
    "没有区别。根据中华人民共和国法律，对任何人犯罪，在适用法律上一律平等。外国籍身份不是影响事实认定、犯罪构成和判决刑期的法定事由。\n",
    "《中华人民共和国刑法》第4条：对任何人犯罪，在适用法律上一律平等。不允许任何人有超越法律的特权。\n",
    "《中华人民共和国刑事诉讼法》第6条：人民法院、人民检察院和公安机关进行刑事诉讼，必须依靠群众，必须以事实为根据，以法律为准绳。对于一切公民，在适用法律上一律平等，在法律面前，不允许有任何特权。'''\n",
    "output_prompt = '外国人在中国不能做什么呢？'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/zy/new_convert/model.py:280: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorIterator.cpp:918.)\n",
      "  attention_scores = torch.mul(\n",
      "100%|██████████| 39/39 [00:32<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "out_texts = predict(input_prompt, output_prompt, 50)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "外国人犯罪案件归基层检察机关管辖吗？\n",
      "根据中华人民共和国法律，基层检察机关可以办理外国人犯罪案件，涉外因素不是影响管辖的法定事由。\n",
      "《<中华人民共和国刑事诉讼法>解释》第393条：第一审涉外刑事案件，除刑事诉讼法第二十条至第二十二条规定的以外，由基层人民法院管辖。必要时，中级人民法院可以指定辖区内若干基层人民法院集中管辖第一审涉外刑事案件，也可以依照刑事诉讼法第二十三条的规定，审理基层人民法院管辖的第一审涉外刑事案件。\n",
      "人民检察院管辖范围与同级人民法院一致。\n",
      "外国人犯罪在犯罪构成、罪名和刑期方面与我国公民犯罪有什么区别吗？\n",
      "没有区别。根据中华人民共和国法律，对任何人犯罪，在适用法律上一律平等。外国籍身份不是影响事实认定、犯罪构成和判决刑期的法定事由。\n",
      "《中华人民共和国刑法》第4条：对任何人犯罪，在适用法律上一律平等。不允许任何人有超越法律的特权。\n",
      "《中华人民共和国刑事诉讼法》第6条：人民法院、人民检察院和公安机关进行刑事诉讼，必须依靠群众，必须以事实为根据，以法律为准绳。对于一切公民，在适用法律上一律平等，在法律面前，不允许有任何特权。\n"
     ]
    }
   ],
   "source": [
    "print(input_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "外国人在中国不能做什么呢？\n",
      "在法律面前，每个公民都是平等的，任何人都不能作超越法律的特权。\n",
      "人民检察院可以办理外国人犯罪案件。但不能对外国人\n"
     ]
    }
   ],
   "source": [
    "print(output_prompt + out_texts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
