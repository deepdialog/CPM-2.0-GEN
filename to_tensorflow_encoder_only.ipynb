{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from transformers import TFT5EncoderModel, TFT5Model\n",
    "from transformers import T5Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenization_enc_dec_encn import EncDecTokenizer\n",
    "tokenizer = EncDecTokenizer('./encn/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = T5Config(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "#     n_positions=self.n_positions,\n",
    "    d_model=4096,\n",
    "    d_ff=10240,\n",
    "    d_kv=4096 // 64,\n",
    "    num_layers=24,\n",
    "    num_heads=64,\n",
    "    relative_attention_num_buckets=32,\n",
    "    dropout_rate=0.0,\n",
    "    initializer_factor=1.0,\n",
    "    eos_token_id=tokenizer.eod_id,\n",
    "    bos_token_id=tokenizer.pad_id,\n",
    "    pad_token_id=tokenizer.pad_id,\n",
    "    decoder_start_token_id=tokenizer.pad_id,\n",
    "    feed_forward_proj='gated-gelu',\n",
    "    tie_word_embeddings=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFT5EncoderModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "strs = tf.TensorSpec(shape=[None, None],\n",
    "                     dtype=tf.int32,\n",
    "                     name=\"input_1\")\n",
    "model._set_inputs(strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(input_ids=tf.constant([[1] * 512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(name):\n",
    "    return state_dict[name].numpy()\n",
    "\n",
    "\n",
    "def get_block_weight(n, t='encoder', name=False, dim=4096):\n",
    "    weights = []\n",
    "    for k, v in state_dict.items():\n",
    "        if t in k and f'blocks.{n}.' in k:\n",
    "            # pytorch和tensorflow版本的weights是矩阵转置的\n",
    "            w = v.numpy()\n",
    "            if 'self_attn.project' in k:\n",
    "                w0, w1, w2 = w[:dim, :], w[dim:dim*2, :], w[dim*2:, :]\n",
    "                w0 = np.transpose(w0)\n",
    "                w1 = np.transpose(w1)\n",
    "                w2 = np.transpose(w2)\n",
    "                weights.append((k, w0))\n",
    "                weights.append((k, w1))\n",
    "                weights.append((k, w2))\n",
    "            elif 'cross_attn.project_q' in k:\n",
    "                w = np.transpose(w)\n",
    "                weights.append((k, w))\n",
    "            elif 'cross_attn.project_kv' in k:\n",
    "                w0, w1 = w[:dim, :], w[dim:, :]\n",
    "                w0 = np.transpose(w0)\n",
    "                w1 = np.transpose(w1)\n",
    "                weights.append((k, w0))\n",
    "                weights.append((k, w1))\n",
    "            else:\n",
    "                if 'dense' in k:\n",
    "                    w = np.transpose(w)\n",
    "                weights.append((k, w))\n",
    "    if 'relative_attention_bias' in weights[3][0]:\n",
    "        weights = weights[3:4] + weights[:3] + weights[4:]\n",
    "    if not name:\n",
    "        weights = [x[1] for x in weights]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('../converted.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new_weights = [get_weight('word_embeds.weight')]\n",
    "for i in range(24):\n",
    "    model_new_weights += get_block_weight(i, t='encoder')\n",
    "model_new_weights += [get_weight('encoder.final_layernorm.weight')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_embeds.weight torch.Size([51968, 4096])\n",
      "lm_head.weight torch.Size([51968, 4096])\n",
      "encoder.word_embeds.weight torch.Size([51968, 4096])\n",
      "encoder.final_layernorm.weight torch.Size([4096])\n",
      "encoder.blocks.0.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.0.self_attn.self_attn.relative_attention_bias.weight torch.Size([32, 64])\n",
      "encoder.blocks.0.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.0.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.0.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.0.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.0.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.0.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.1.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.1.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.1.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.1.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.1.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.1.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.1.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.2.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.2.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.2.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.2.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.2.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.2.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.2.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.3.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.3.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.3.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.3.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.3.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.3.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.3.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.4.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.4.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.4.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.4.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.4.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.4.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.4.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.5.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.5.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.5.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.5.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.5.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.5.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.5.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.6.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.6.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.6.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.6.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.6.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.6.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.6.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.7.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.7.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.7.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.7.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.7.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.7.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.7.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.8.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.8.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.8.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.8.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.8.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.8.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.8.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.9.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.9.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.9.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.9.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.9.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.9.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.9.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.10.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.10.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.10.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.10.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.10.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.10.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.10.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.11.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.11.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.11.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.11.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.11.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.11.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.11.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.12.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.12.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.12.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.12.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.12.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.12.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.12.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.13.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.13.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.13.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.13.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.13.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.13.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.13.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.14.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.14.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.14.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.14.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.14.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.14.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.14.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.15.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.15.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.15.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.15.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.15.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.15.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.15.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.16.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.16.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.16.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.16.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.16.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.16.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.16.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.17.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.17.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.17.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.17.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.17.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.17.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.17.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.18.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.18.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.18.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.18.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.18.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.18.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.18.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.19.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.19.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.19.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.19.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.19.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.19.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.19.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.20.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.20.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.20.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.20.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.20.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.20.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.20.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.21.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.21.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.21.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.21.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.21.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.21.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.21.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.22.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.22.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.22.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.22.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.22.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.22.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.22.ff.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.23.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "encoder.blocks.23.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "encoder.blocks.23.self_attn.layer_norm.weight torch.Size([4096])\n",
      "encoder.blocks.23.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.23.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "encoder.blocks.23.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "encoder.blocks.23.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.word_embeds.weight torch.Size([51968, 4096])\n",
      "decoder.final_layernorm.weight torch.Size([4096])\n",
      "decoder.blocks.0.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.0.self_attn.self_attn.relative_attention_bias.weight torch.Size([32, 64])\n",
      "decoder.blocks.0.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.0.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.0.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.0.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.0.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.0.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.0.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.0.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.0.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.0.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.1.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.1.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.1.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.1.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.1.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.1.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.1.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.1.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.1.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.1.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.1.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.2.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.2.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.2.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.2.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.2.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.2.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.2.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.2.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.2.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.2.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.2.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.3.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.3.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.3.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.3.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.3.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.3.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.3.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.3.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.3.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.3.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.3.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.4.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.4.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.4.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.4.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.4.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.4.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.4.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.4.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.4.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.4.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.4.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.5.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.5.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.5.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.5.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.5.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.5.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.5.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.5.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.5.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.5.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.5.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.6.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.6.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.6.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.6.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.6.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.6.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.6.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.6.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.6.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.6.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.6.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.7.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.7.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.7.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.7.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.7.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.7.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.7.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.7.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.7.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.7.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.7.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.8.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.8.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.8.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.8.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.8.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.8.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.8.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.8.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.8.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.8.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.8.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.9.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.9.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.9.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.9.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.9.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.9.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.9.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.9.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.9.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.9.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.9.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.10.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.10.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.10.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.10.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.10.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.10.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.10.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.10.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.10.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.10.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.10.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.11.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.11.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.11.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.11.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.11.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.11.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.11.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.11.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.11.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.11.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.11.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.12.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.12.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.12.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.12.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.12.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.12.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.12.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.12.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.12.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.12.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.12.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.13.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.13.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.13.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.13.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.13.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.13.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.13.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.13.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.13.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.13.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.13.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.14.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.14.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.14.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.14.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.14.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.14.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.14.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.14.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.14.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.14.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.14.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.15.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.15.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.15.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.15.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.15.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.15.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.15.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.15.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.15.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.15.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.15.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.16.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.16.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.16.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.16.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.16.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.16.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.16.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.16.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.16.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.16.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.16.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.17.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.17.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.17.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.17.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.17.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.17.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.17.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.17.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.17.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.17.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.17.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.18.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.18.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.18.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.18.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.18.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.18.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.18.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.18.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.18.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.18.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.18.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.19.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.19.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.19.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.19.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.19.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.19.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.19.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.19.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.19.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.19.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.19.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.20.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.20.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.20.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.20.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.20.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.20.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.20.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.20.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.20.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.20.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.20.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.21.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.21.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.21.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.21.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.21.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.21.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.21.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.21.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.21.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.21.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.21.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.22.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.22.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.22.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.22.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.22.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.22.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.22.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.22.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.22.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.22.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.22.ff.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.23.self_attn.self_attn.project.weight torch.Size([12288, 4096])\n",
      "decoder.blocks.23.self_attn.self_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.23.self_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.23.cross_attn.cross_attn.project_q.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.23.cross_attn.cross_attn.project_kv.weight torch.Size([8192, 4096])\n",
      "decoder.blocks.23.cross_attn.cross_attn.dense.weight torch.Size([4096, 4096])\n",
      "decoder.blocks.23.cross_attn.layer_norm.weight torch.Size([4096])\n",
      "decoder.blocks.23.ff.dense_relu_dense.wi_0.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.23.ff.dense_relu_dense.wi_1.weight torch.Size([10240, 4096])\n",
      "decoder.blocks.23.ff.dense_relu_dense.wo.weight torch.Size([4096, 10240])\n",
      "decoder.blocks.23.ff.layer_norm.weight torch.Size([4096])\n"
     ]
    }
   ],
   "source": [
    "for k, v in state_dict.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51968, 4096)\n",
      "(32, 64)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 10240)\n",
      "(4096, 10240)\n",
      "(10240, 4096)\n",
      "(4096,)\n",
      "(4096,)\n"
     ]
    }
   ],
   "source": [
    "for k in model_new_weights:\n",
    "    print(k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared/shared/weight:0 (51968, 4096)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/relative_attention_bias/embeddings:0 (32, 64)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._0/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._1/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._1/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._1/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._1/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._1/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._1/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._1/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._1/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._1/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._2/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._2/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._2/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._2/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._2/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._2/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._2/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._2/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._2/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._3/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._3/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._3/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._3/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._3/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._3/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._3/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._3/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._3/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._4/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._4/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._4/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._4/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._4/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._4/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._4/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._4/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._4/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._5/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._5/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._5/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._5/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._5/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._5/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._5/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._5/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._5/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._6/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._6/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._6/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._6/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._6/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._6/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._6/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._6/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._6/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._7/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._7/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._7/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._7/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._7/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._7/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._7/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._7/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._7/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._8/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._8/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._8/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._8/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._8/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._8/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._8/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._8/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._8/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._9/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._9/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._9/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._9/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._9/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._9/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._9/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._9/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._9/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._10/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._10/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._10/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._10/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._10/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._10/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._10/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._10/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._10/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._11/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._11/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._11/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._11/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._11/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._11/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._11/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._11/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._11/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._12/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._12/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._12/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._12/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._12/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._12/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._12/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._12/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._12/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._13/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._13/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._13/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._13/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._13/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._13/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._13/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._13/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._13/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._14/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._14/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._14/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._14/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._14/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._14/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._14/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._14/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._14/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._15/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._15/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._15/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._15/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._15/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._15/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._15/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._15/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._15/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._16/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._16/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._16/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._16/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._16/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._16/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._16/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._16/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._16/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._17/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._17/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._17/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._17/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._17/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._17/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._17/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._17/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._17/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._18/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._18/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._18/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._18/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._18/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._18/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._18/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._18/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._18/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._19/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._19/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._19/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._19/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._19/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._19/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._19/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._19/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._19/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._20/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._20/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._20/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._20/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._20/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._20/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._20/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._20/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._20/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._21/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._21/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._21/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._21/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._21/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._21/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._21/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._21/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._21/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._22/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._22/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._22/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._22/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._22/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._22/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._22/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._22/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._22/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._23/layer_._0/SelfAttention/q/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._23/layer_._0/SelfAttention/k/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._23/layer_._0/SelfAttention/v/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._23/layer_._0/SelfAttention/o/kernel:0 (4096, 4096)\n",
      "tf_t5encoder_model/encoder/block_._23/layer_._0/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/block_._23/layer_._1/DenseReluDense/wi_0/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._23/layer_._1/DenseReluDense/wi_1/kernel:0 (4096, 10240)\n",
      "tf_t5encoder_model/encoder/block_._23/layer_._1/DenseReluDense/wo/kernel:0 (10240, 4096)\n",
      "tf_t5encoder_model/encoder/block_._23/layer_._1/layer_norm/weight:0 (4096,)\n",
      "tf_t5encoder_model/encoder/final_layer_norm/weight:0 (4096,)\n"
     ]
    }
   ],
   "source": [
    "for x in model.variables:\n",
    "    print(x.name, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(model_new_weights) == len(model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(model_new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.563 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "input_text = '''当地时间9月6日是美国劳工节，但就在这一天，上千万美国劳动者却陷入新的困境。因为美国政府为疫情期间失业者提供的主要救助同日到期，而且白宫表示没有进一步延长救助的计划。\n",
    "在德尔塔变异株已把美国推入新一轮疫情的背景下，失业救济的突然“断供”意味着有上千万美国人将全部或部分失去他们的生活来源。'''\n",
    "input_ids = tf.constant([tokenizer.encode(input_text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 10min 15s, total: 11min 34s\n",
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out = model(\n",
    "    input_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 102, 4096])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fd4bc0af2e0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fd4bc0af2e0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_96_layer_call_fn, dropout_96_layer_call_and_return_conditional_losses, block_._0_layer_call_fn while saving (showing 5 of 2170). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cpm_2_0_tf_encoder/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cpm_2_0_tf_encoder/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('cpm_2_0_tf_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19G\tcpm_2_0_tf_encoder\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh 'cpm_2_0_tf_encoder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-21 01:22:26.813910: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-21 01:22:26.813940: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/opt/conda/lib/python3.8/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-09-21 01:22:29.840769: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-09-21 01:22:29.840797: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-09-21 01:22:29.840820: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (iZuf6fokcl2k1pwfopz0n4Z): /proc/driver/nvidia/version does not exist\n",
      "2021-09-21 01:22:29.841083: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-21 01:22:29,850 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2021-09-21 01:22:47,486 - INFO - Signatures found in model: [serving_default].\n",
      "2021-09-21 01:22:47,486 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2021-09-21 01:22:47,488 - INFO - Output names: ['last_hidden_state']\n",
      "2021-09-21 01:22:47.653547: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2021-09-21 01:22:47.653842: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2021-09-21 01:22:48.094536: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 6108 nodes (5885), 7729 edges (7506), time = 265.122ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 11.05ms.\n",
      "\n",
      "2021-09-21 01:25:13,130 - INFO - Using tensorflow=2.6.0, onnx=1.9.0, tf2onnx=1.9.2/0f28b7\n",
      "2021-09-21 01:25:13,131 - INFO - Using opset <onnx, 13>\n",
      "2021-09-21 01:28:54,996 - INFO - Computed 388 values for constant folding\n",
      "2021-09-21 01:30:21,228 - INFO - folding node using tf type=Identity, name=Func/StatefulPartitionedCall/input/_1\n",
      "2021-09-21 01:30:22,740 - INFO - folding node using tf type=Identity, name=Func/StatefulPartitionedCall/input/_6\n",
      "2021-09-21 01:30:22,741 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/q/Tensordot/concat\n",
      "2021-09-21 01:30:22,741 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/k/Tensordot/concat\n",
      "2021-09-21 01:30:22,741 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/v/Tensordot/concat\n",
      "2021-09-21 01:30:22,741 - INFO - folding node using tf type=Cast, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/truediv/Cast_1\n",
      "2021-09-21 01:30:22,741 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/o/Tensordot/concat\n",
      "2021-09-21 01:30:22,742 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._0/layer_._1/DenseReluDense/wi_0/Tensordot/concat\n",
      "2021-09-21 01:30:22,742 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._0/layer_._1/DenseReluDense/wi_1/Tensordot/concat\n",
      "2021-09-21 01:30:22,742 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._0/layer_._1/DenseReluDense/wo/Tensordot/concat\n",
      "2021-09-21 01:30:22,742 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._1/layer_._0/SelfAttention/q/Tensordot/concat\n",
      "2021-09-21 01:30:22,742 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._1/layer_._0/SelfAttention/k/Tensordot/concat\n",
      "2021-09-21 01:30:22,742 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._1/layer_._0/SelfAttention/v/Tensordot/concat\n",
      "2021-09-21 01:30:22,742 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._1/layer_._0/SelfAttention/o/Tensordot/concat\n",
      "2021-09-21 01:30:22,742 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._1/layer_._1/DenseReluDense/wi_0/Tensordot/concat\n",
      "2021-09-21 01:30:22,743 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._1/layer_._1/DenseReluDense/wi_1/Tensordot/concat\n",
      "2021-09-21 01:30:22,743 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._1/layer_._1/DenseReluDense/wo/Tensordot/concat\n",
      "2021-09-21 01:30:22,743 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._2/layer_._0/SelfAttention/q/Tensordot/concat\n",
      "2021-09-21 01:30:22,743 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._2/layer_._0/SelfAttention/k/Tensordot/concat\n",
      "2021-09-21 01:30:22,743 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._2/layer_._0/SelfAttention/v/Tensordot/concat\n",
      "2021-09-21 01:30:22,743 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._2/layer_._0/SelfAttention/o/Tensordot/concat\n",
      "2021-09-21 01:30:22,743 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._2/layer_._1/DenseReluDense/wi_0/Tensordot/concat\n",
      "2021-09-21 01:30:22,743 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._2/layer_._1/DenseReluDense/wi_1/Tensordot/concat\n",
      "2021-09-21 01:30:22,744 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._2/layer_._1/DenseReluDense/wo/Tensordot/concat\n",
      "2021-09-21 01:30:22,744 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._3/layer_._0/SelfAttention/q/Tensordot/concat\n",
      "2021-09-21 01:30:22,745 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._3/layer_._0/SelfAttention/k/Tensordot/concat\n",
      "2021-09-21 01:30:22,745 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._3/layer_._0/SelfAttention/v/Tensordot/concat\n",
      "2021-09-21 01:30:22,745 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._3/layer_._0/SelfAttention/o/Tensordot/concat\n",
      "2021-09-21 01:30:22,745 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._3/layer_._1/DenseReluDense/wi_0/Tensordot/concat\n",
      "2021-09-21 01:30:22,745 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._3/layer_._1/DenseReluDense/wi_1/Tensordot/concat\n",
      "2021-09-21 01:30:22,745 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._3/layer_._1/DenseReluDense/wo/Tensordot/concat\n",
      "2021-09-21 01:30:22,745 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._4/layer_._0/SelfAttention/q/Tensordot/concat\n",
      "2021-09-21 01:30:22,745 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._4/layer_._0/SelfAttention/k/Tensordot/concat\n",
      "2021-09-21 01:30:22,746 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._4/layer_._0/SelfAttention/v/Tensordot/concat\n",
      "2021-09-21 01:30:22,746 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._4/layer_._0/SelfAttention/o/Tensordot/concat\n",
      "2021-09-21 01:30:22,746 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._4/layer_._1/DenseReluDense/wi_0/Tensordot/concat\n",
      "2021-09-21 01:30:22,746 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._4/layer_._1/DenseReluDense/wi_1/Tensordot/concat\n",
      "2021-09-21 01:30:22,746 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._4/layer_._1/DenseReluDense/wo/Tensordot/concat\n",
      "2021-09-21 01:30:22,746 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._5/layer_._0/SelfAttention/q/Tensordot/concat\n",
      "2021-09-21 01:30:22,746 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._5/layer_._0/SelfAttention/k/Tensordot/concat\n",
      "2021-09-21 01:30:22,746 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._5/layer_._0/SelfAttention/v/Tensordot/concat\n",
      "2021-09-21 01:30:22,746 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._5/layer_._0/SelfAttention/o/Tensordot/concat\n",
      "2021-09-21 01:30:22,747 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._5/layer_._1/DenseReluDense/wi_0/Tensordot/concat\n",
      "2021-09-21 01:30:22,747 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._5/layer_._1/DenseReluDense/wi_1/Tensordot/concat\n",
      "2021-09-21 01:30:22,747 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._5/layer_._1/DenseReluDense/wo/Tensordot/concat\n",
      "2021-09-21 01:30:22,747 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._6/layer_._0/SelfAttention/q/Tensordot/concat\n",
      "2021-09-21 01:30:22,747 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._6/layer_._0/SelfAttention/k/Tensordot/concat\n",
      "2021-09-21 01:30:22,747 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._6/layer_._0/SelfAttention/v/Tensordot/concat\n",
      "2021-09-21 01:30:22,747 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._6/layer_._0/SelfAttention/o/Tensordot/concat\n",
      "2021-09-21 01:30:22,747 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._6/layer_._1/DenseReluDense/wi_0/Tensordot/concat\n",
      "2021-09-21 01:30:22,748 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._6/layer_._1/DenseReluDense/wi_1/Tensordot/concat\n",
      "2021-09-21 01:30:22,748 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._6/layer_._1/DenseReluDense/wo/Tensordot/concat\n",
      "2021-09-21 01:30:22,748 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._7/layer_._0/SelfAttention/q/Tensordot/concat\n",
      "2021-09-21 01:30:22,748 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._7/layer_._0/SelfAttention/k/Tensordot/concat\n",
      "2021-09-21 01:30:22,748 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._7/layer_._0/SelfAttention/v/Tensordot/concat\n",
      "2021-09-21 01:30:22,748 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._7/layer_._0/SelfAttention/o/Tensordot/concat\n",
      "2021-09-21 01:30:22,748 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._7/layer_._1/DenseReluDense/wi_0/Tensordot/concat\n",
      "2021-09-21 01:30:22,748 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._7/layer_._1/DenseReluDense/wi_1/Tensordot/concat\n",
      "2021-09-21 01:30:22,748 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._7/layer_._1/DenseReluDense/wo/Tensordot/concat\n",
      "2021-09-21 01:30:22,749 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._8/layer_._0/SelfAttention/q/Tensordot/concat\n",
      "2021-09-21 01:30:22,749 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._8/layer_._0/SelfAttention/k/Tensordot/concat\n",
      "2021-09-21 01:30:22,749 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._8/layer_._0/SelfAttention/v/Tensordot/concat\n",
      "2021-09-21 01:30:22,749 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._8/layer_._0/SelfAttention/o/Tensordot/concat\n",
      "2021-09-21 01:30:22,749 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._8/layer_._1/DenseReluDense/wi_0/Tensordot/concat\n",
      "2021-09-21 01:30:22,749 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._8/layer_._1/DenseReluDense/wi_1/Tensordot/concat\n",
      "2021-09-21 01:30:22,749 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._8/layer_._1/DenseReluDense/wo/Tensordot/concat\n",
      "2021-09-21 01:30:22,749 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._9/layer_._0/SelfAttention/q/Tensordot/concat\n",
      "2021-09-21 01:30:22,749 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._9/layer_._0/SelfAttention/k/Tensordot/concat\n",
      "2021-09-21 01:30:22,750 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._9/layer_._0/SelfAttention/v/Tensordot/concat\n",
      "2021-09-21 01:30:22,750 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._9/layer_._0/SelfAttention/o/Tensordot/concat\n",
      "2021-09-21 01:30:22,750 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._9/layer_._1/DenseReluDense/wi_0/Tensordot/concat\n",
      "2021-09-21 01:30:22,750 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._9/layer_._1/DenseReluDense/wi_1/Tensordot/concat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-21 01:30:22,750 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._9/layer_._1/DenseReluDense/wo/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,750 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._10/layer_._0/SelfAttention/q/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,750 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._10/layer_._0/SelfAttention/k/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,750 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._10/layer_._0/SelfAttention/v/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,750 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._10/layer_._0/SelfAttention/o/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,751 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._10/layer_._1/DenseReluDense/wi_0/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,751 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._10/layer_._1/DenseReluDense/wi_1/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,751 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._10/layer_._1/DenseReluDense/wo/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,751 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._11/layer_._0/SelfAttention/q/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,751 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._11/layer_._0/SelfAttention/k/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,751 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._11/layer_._0/SelfAttention/v/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,751 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._11/layer_._0/SelfAttention/o/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,751 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._11/layer_._1/DenseReluDense/wi_0/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,752 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._11/layer_._1/DenseReluDense/wi_1/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,752 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._11/layer_._1/DenseReluDense/wo/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,752 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._12/layer_._0/SelfAttention/q/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,752 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._12/layer_._0/SelfAttention/k/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,752 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._12/layer_._0/SelfAttention/v/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,752 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._12/layer_._0/SelfAttention/o/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,752 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._12/layer_._1/DenseReluDense/wi_0/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,752 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._12/layer_._1/DenseReluDense/wi_1/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,752 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._12/layer_._1/DenseReluDense/wo/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,753 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._13/layer_._0/SelfAttention/q/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,753 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._13/layer_._0/SelfAttention/k/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,753 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._13/layer_._0/SelfAttention/v/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,753 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._13/layer_._0/SelfAttention/o/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,753 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._13/layer_._1/DenseReluDense/wi_0/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,753 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._13/layer_._1/DenseReluDense/wi_1/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,753 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._13/layer_._1/DenseReluDense/wo/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,753 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._14/layer_._0/SelfAttention/q/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,753 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._14/layer_._0/SelfAttention/k/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,754 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._14/layer_._0/SelfAttention/v/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,754 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._14/layer_._0/SelfAttention/o/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,754 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._14/layer_._1/DenseReluDense/wi_0/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,754 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._14/layer_._1/DenseReluDense/wi_1/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,754 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._14/layer_._1/DenseReluDense/wo/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,754 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._15/layer_._0/SelfAttention/q/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,754 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._15/layer_._0/SelfAttention/k/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,754 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._15/layer_._0/SelfAttention/v/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,754 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._15/layer_._0/SelfAttention/o/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,755 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._15/layer_._1/DenseReluDense/wi_0/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,755 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._15/layer_._1/DenseReluDense/wi_1/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,755 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._15/layer_._1/DenseReluDense/wo/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,755 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._16/layer_._0/SelfAttention/q/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,755 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._16/layer_._0/SelfAttention/k/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,755 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._16/layer_._0/SelfAttention/v/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,755 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._16/layer_._0/SelfAttention/o/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,755 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._16/layer_._1/DenseReluDense/wi_0/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,755 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._16/layer_._1/DenseReluDense/wi_1/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,756 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._16/layer_._1/DenseReluDense/wo/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,756 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._17/layer_._0/SelfAttention/q/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,756 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._17/layer_._0/SelfAttention/k/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,756 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._17/layer_._0/SelfAttention/v/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,756 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._17/layer_._0/SelfAttention/o/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,756 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._17/layer_._1/DenseReluDense/wi_0/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,756 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._17/layer_._1/DenseReluDense/wi_1/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,756 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._17/layer_._1/DenseReluDense/wo/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,757 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._18/layer_._0/SelfAttention/q/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,757 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._18/layer_._0/SelfAttention/k/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,757 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._18/layer_._0/SelfAttention/v/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,757 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._18/layer_._0/SelfAttention/o/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,757 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._18/layer_._1/DenseReluDense/wi_0/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,757 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._18/layer_._1/DenseReluDense/wi_1/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,757 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._18/layer_._1/DenseReluDense/wo/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,757 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._19/layer_._0/SelfAttention/q/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,757 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._19/layer_._0/SelfAttention/k/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,758 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._19/layer_._0/SelfAttention/v/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,758 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._19/layer_._0/SelfAttention/o/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,758 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._19/layer_._1/DenseReluDense/wi_0/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,758 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._19/layer_._1/DenseReluDense/wi_1/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,758 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._19/layer_._1/DenseReluDense/wo/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,758 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._20/layer_._0/SelfAttention/q/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,758 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._20/layer_._0/SelfAttention/k/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,758 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._20/layer_._0/SelfAttention/v/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,758 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._20/layer_._0/SelfAttention/o/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,759 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._20/layer_._1/DenseReluDense/wi_0/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,759 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._20/layer_._1/DenseReluDense/wi_1/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,759 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._20/layer_._1/DenseReluDense/wo/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,759 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._21/layer_._0/SelfAttention/q/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,759 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._21/layer_._0/SelfAttention/k/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,759 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._21/layer_._0/SelfAttention/v/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,759 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._21/layer_._0/SelfAttention/o/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,759 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._21/layer_._1/DenseReluDense/wi_0/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,759 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._21/layer_._1/DenseReluDense/wi_1/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,760 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._21/layer_._1/DenseReluDense/wo/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,760 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._22/layer_._0/SelfAttention/q/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,760 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._22/layer_._0/SelfAttention/k/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,760 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._22/layer_._0/SelfAttention/v/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,760 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._22/layer_._0/SelfAttention/o/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,760 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._22/layer_._1/DenseReluDense/wi_0/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,760 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._22/layer_._1/DenseReluDense/wi_1/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,760 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._22/layer_._1/DenseReluDense/wo/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,760 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._23/layer_._0/SelfAttention/q/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,761 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._23/layer_._0/SelfAttention/k/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,761 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._23/layer_._0/SelfAttention/v/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,761 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._23/layer_._0/SelfAttention/o/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,761 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._23/layer_._1/DenseReluDense/wi_0/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,761 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._23/layer_._1/DenseReluDense/wi_1/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,761 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._23/layer_._1/DenseReluDense/wo/Tensordot/concat\r\n",
      "2021-09-21 01:30:22,761 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._0/layer_._0/layer_norm/ReadVariableOp\r\n",
      "2021-09-21 01:30:22,761 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-21 01:30:22,908 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:23,052 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:23,197 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:23,341 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._0/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:23,342 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._0/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:23,701 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._0/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:24,062 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._0/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:24,422 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._1/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:24,422 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._1/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:24,567 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._1/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:24,712 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._1/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:24,857 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._1/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:25,003 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._1/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:25,004 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._1/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:25,364 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._1/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:25,725 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._1/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:26,085 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._2/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:26,085 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._2/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:26,230 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._2/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:26,375 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._2/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:26,519 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._2/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:26,664 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._2/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:26,665 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._2/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:27,023 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._2/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:27,381 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._2/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:27,740 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._3/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:27,740 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._3/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:27,884 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._3/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:28,030 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._3/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:28,174 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._3/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:28,319 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._3/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:28,319 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._3/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:28,679 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._3/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:29,038 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._3/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:29,395 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._4/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:29,396 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._4/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:29,541 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._4/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:29,686 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._4/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:29,830 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._4/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:29,975 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._4/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:29,976 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._4/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:30,335 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._4/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:30,692 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._4/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:31,051 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._5/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:31,052 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._5/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-21 01:30:31,197 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._5/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:31,341 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._5/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:31,486 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._5/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:31,630 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._5/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:31,630 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._5/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:31,993 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._5/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:32,350 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._5/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:32,713 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._6/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:32,713 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._6/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:32,868 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._6/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:33,011 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._6/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:33,156 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._6/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:33,299 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._6/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:33,300 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._6/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:33,664 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._6/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:34,024 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._6/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:34,385 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._7/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:34,386 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._7/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:34,534 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._7/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:34,678 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._7/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:34,825 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._7/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:34,969 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._7/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:34,970 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._7/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:35,330 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._7/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:35,695 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._7/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:36,059 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._8/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:36,059 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._8/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:36,204 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._8/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:36,353 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._8/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:36,497 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._8/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:36,642 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._8/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:36,642 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._8/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:37,009 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._8/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:37,371 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._8/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:37,735 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._9/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:37,735 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._9/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:37,883 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._9/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:38,028 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._9/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:38,169 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._9/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:38,314 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._9/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:38,314 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._9/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:38,680 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._9/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:39,045 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._9/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:39,408 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._10/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:39,408 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._10/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-21 01:30:39,557 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._10/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:39,701 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._10/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:39,850 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._10/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:39,995 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._10/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:39,995 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._10/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:40,359 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._10/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:40,723 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._10/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:41,086 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._11/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:41,086 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._11/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:41,234 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._11/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:41,378 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._11/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:41,545 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._11/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:41,689 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._11/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:41,690 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._11/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:42,049 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._11/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:42,428 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._11/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:42,786 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._12/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:42,786 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._12/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:42,932 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._12/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:43,077 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._12/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:43,221 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._12/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:43,387 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._12/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:43,387 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._12/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:43,747 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._12/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:44,106 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._12/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:44,486 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._13/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:44,486 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._13/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:44,630 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._13/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:44,775 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._13/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:44,920 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._13/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:45,065 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._13/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:45,066 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._13/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:45,445 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._13/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:45,804 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._13/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:46,183 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._14/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:46,183 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._14/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:46,328 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._14/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:46,472 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._14/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:46,617 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._14/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:46,764 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._14/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:46,764 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._14/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:47,124 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._14/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:47,484 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._14/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:47,844 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._15/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:47,844 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._15/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-21 01:30:47,990 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._15/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:48,134 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._15/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:48,279 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._15/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:48,424 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._15/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:48,425 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._15/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:48,784 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._15/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:49,143 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._15/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:49,507 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._16/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:49,507 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._16/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:49,656 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._16/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:49,800 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._16/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:49,960 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._16/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:50,104 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._16/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:50,104 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._16/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:50,480 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._16/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:50,838 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._16/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:51,207 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._17/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:51,207 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._17/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:51,351 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._17/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:51,496 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._17/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:51,640 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._17/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:51,788 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._17/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:51,788 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._17/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:52,226 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._17/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:52,675 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._17/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:53,106 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._18/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:53,106 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._18/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:53,255 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._18/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:53,399 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._18/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:53,548 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._18/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:53,697 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._18/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:53,698 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._18/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:54,152 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._18/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:54,605 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._18/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:55,002 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._19/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:55,002 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._19/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:55,151 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._19/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:55,296 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._19/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:55,445 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._19/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:55,591 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._19/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:55,592 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._19/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:56,022 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._19/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:56,476 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._19/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:56,904 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._20/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:56,905 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._20/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-21 01:30:57,055 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._20/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:57,200 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._20/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:57,349 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._20/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:57,497 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._20/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:57,497 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._20/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:57,899 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._20/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:58,347 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._20/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:58,791 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._21/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:58,791 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._21/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:58,943 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._21/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:59,092 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._21/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:59,238 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._21/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:59,392 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._21/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:30:59,393 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._21/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:30:59,773 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._21/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:31:00,163 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._21/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:31:00,568 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._22/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:31:00,568 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._22/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:31:00,719 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._22/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:31:00,866 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._22/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:31:01,015 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._22/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:31:01,178 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._22/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:31:01,178 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._22/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:31:01,678 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._22/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:31:02,157 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._22/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:31:02,638 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._23/layer_._0/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:31:02,638 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._23/layer_._0/SelfAttention/q/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:31:02,798 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._23/layer_._0/SelfAttention/k/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:31:02,958 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._23/layer_._0/SelfAttention/v/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:31:03,115 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._23/layer_._0/SelfAttention/o/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:31:03,275 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._23/layer_._1/layer_norm/ReadVariableOp\n",
      "2021-09-21 01:31:03,275 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._23/layer_._1/DenseReluDense/wi_0/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:31:03,733 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._23/layer_._1/DenseReluDense/wi_1/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:31:04,193 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._23/layer_._1/DenseReluDense/wo/Tensordot/ReadVariableOp\n",
      "2021-09-21 01:31:04,647 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/tf_t5encoder_model/encoder/final_layer_norm/ReadVariableOp\n",
      "2021-09-21 01:31:08,322 - INFO - Optimizing ONNX model\n",
      "2021-09-21 01:35:44,367 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._8/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__3439'.\n",
      "2021-09-21 01:35:44,374 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._22/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__3490'.\n",
      "2021-09-21 01:35:44,381 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._9/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__3541'.\n",
      "2021-09-21 01:35:44,388 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._13/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__3592'.\n",
      "2021-09-21 01:35:44,396 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._7/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__3643'.\n",
      "2021-09-21 01:35:44,403 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._23/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__3694'.\n",
      "2021-09-21 01:35:44,410 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._3/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__3745'.\n",
      "2021-09-21 01:35:44,417 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._0/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__3796'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-21 01:35:44,424 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._17/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__3847'.\n",
      "2021-09-21 01:35:44,431 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._11/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__3898'.\n",
      "2021-09-21 01:35:44,439 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._6/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__3949'.\n",
      "2021-09-21 01:35:44,446 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._2/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__4000'.\n",
      "2021-09-21 01:35:44,453 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._18/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__4051'.\n",
      "2021-09-21 01:35:44,460 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._5/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__4102'.\n",
      "2021-09-21 01:35:44,467 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._19/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__4153'.\n",
      "2021-09-21 01:35:44,474 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._10/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__4204'.\n",
      "2021-09-21 01:35:44,482 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._4/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__4255'.\n",
      "2021-09-21 01:35:44,489 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._14/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__4306'.\n",
      "2021-09-21 01:35:44,496 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._15/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__4357'.\n",
      "2021-09-21 01:35:44,504 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._12/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__4408'.\n",
      "2021-09-21 01:35:44,511 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._21/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__4459'.\n",
      "2021-09-21 01:35:44,519 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._20/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__4510'.\n",
      "2021-09-21 01:35:44,527 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._16/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__4561'.\n",
      "2021-09-21 01:35:44,535 - INFO - replacing einsum node 'StatefulPartitionedCall/tf_t5encoder_model/encoder/block_._1/layer_._0/SelfAttention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__4612'.\n",
      "2021-09-21 01:37:17,675 - INFO - After optimization: Cast -411 (640->229), Concat -216 (434->218), Const -2984 (3241->257), ConstantOfShape +24 (0->24), Einsum -24 (24->0), Gather -120 (338->218), GlobalAveragePool +49 (0->49), Identity -105 (105->0), MatMul +24 (192->216), Max +24 (0->24), Range -1 (2->1), ReduceMean -49 (49->0), ReduceProd -288 (336->48), Reshape -49 (434->385), Squeeze -2 (27->25), Sub +24 (2->26), Transpose -96 (265->169), Unsqueeze -652 (704->52)\n",
      "2021-09-21 01:39:00,366 - INFO - \n",
      "2021-09-21 01:39:00,367 - INFO - Successfully converted TensorFlow model cpm_2_0_tf_encoder to ONNX\n",
      "2021-09-21 01:39:00,367 - INFO - Model inputs: ['input_1']\n",
      "2021-09-21 01:39:00,367 - INFO - Model outputs: ['last_hidden_state']\n",
      "2021-09-21 01:39:00,367 - INFO - Zipped ONNX model is saved at cpm_2_0_encoder_onnx.zip. Unzip before opening in onnxruntime.\n"
     ]
    }
   ],
   "source": [
    "!python -m tf2onnx.convert \\\n",
    "    --large_model \\\n",
    "    --saved-model 'cpm_2_0_tf_encoder' \\\n",
    "    --opset 13 --output \\\n",
    "    cpm_2_0_encoder_onnx.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert\t\t\t       test_tf_encoder.ipynb\r\n",
      "configuration_enc_dec.py       test_tokenizer.ipynb\r\n",
      "convert_multi_to_single.ipynb  tokenization_enc_dec_encn.py\r\n",
      "cpm_2_0_encoder_onnx.zip       tokenization_enc_dec.py\r\n",
      "cpm_2_0_tf_encoder\t       to_pytorch_encoder_only.ipynb\r\n",
      "encn\t\t\t       to_pytorch.ipynb\r\n",
      "model.py\t\t       to_tensorflow_encoder_only.ipynb\r\n",
      "onnx-test.ipynb\t\t       to_tensorflow.ipynb\r\n",
      "__pycache__\t\t       Untitled.ipynb\r\n",
      "README.md\t\t       vocab.txt\r\n",
      "test_model_generation.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ../cpm_2_0_encoder_onnx.zip\n",
      " extracting: __MODEL_PROTO.onnx      \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_final_layer_norm_ReadVariableOp__393_0  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._9_layer_._1_layer_norm_ReadVariableOp__263_1  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._9_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__266_2  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._9_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__265_3  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._9_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__264_4  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._9_layer_._0_layer_norm_ReadVariableOp__258_5  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._9_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__261_6  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._9_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__259_7  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._9_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__262_8  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._9_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__260_9  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._8_layer_._1_layer_norm_ReadVariableOp__254_10  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._8_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__257_11  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._8_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__256_12  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._8_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__255_13  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._8_layer_._0_layer_norm_ReadVariableOp__249_14  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._8_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__252_15  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._8_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__250_16  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._8_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__253_17  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._8_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__251_18  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._7_layer_._1_layer_norm_ReadVariableOp__245_19  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._7_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__248_20  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._7_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__247_21  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._7_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__246_22  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._7_layer_._0_layer_norm_ReadVariableOp__240_23  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._7_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__243_24  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._7_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__241_25  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._7_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__244_26  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._7_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__242_27  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._6_layer_._1_layer_norm_ReadVariableOp__236_28  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._6_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__239_29  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._6_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__238_30  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._6_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__237_31  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._6_layer_._0_layer_norm_ReadVariableOp__231_32  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._6_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__234_33  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._6_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__232_34  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._6_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__235_35  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._6_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__233_36  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._5_layer_._1_layer_norm_ReadVariableOp__227_37  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._5_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__230_38  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._5_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__229_39  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._5_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__228_40  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._5_layer_._0_layer_norm_ReadVariableOp__222_41  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._5_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__225_42  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._5_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__223_43  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._5_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__226_44  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._5_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__224_45  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._4_layer_._1_layer_norm_ReadVariableOp__218_46  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._4_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__221_47  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._4_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__220_48  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._4_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__219_49  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._4_layer_._0_layer_norm_ReadVariableOp__213_50  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._4_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__216_51  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._4_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__214_52  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._4_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__217_53  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._4_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__215_54  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._3_layer_._1_layer_norm_ReadVariableOp__209_55  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._3_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__212_56  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._3_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__211_57  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._3_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__210_58  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._3_layer_._0_layer_norm_ReadVariableOp__204_59  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._3_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__207_60  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._3_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__205_61  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._3_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__208_62  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._3_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__206_63  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._23_layer_._1_layer_norm_ReadVariableOp__389_64  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._23_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__392_65  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._23_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__391_66  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._23_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__390_67  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._23_layer_._0_layer_norm_ReadVariableOp__384_68  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._23_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__387_69  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._23_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__385_70  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._23_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__388_71  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._23_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__386_72  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._22_layer_._1_layer_norm_ReadVariableOp__380_73  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._22_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__383_74  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._22_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__382_75  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._22_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__381_76  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._22_layer_._0_layer_norm_ReadVariableOp__375_77  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._22_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__378_78  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._22_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__376_79  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._22_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__379_80  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._22_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__377_81  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._21_layer_._1_layer_norm_ReadVariableOp__371_82  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._21_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__374_83  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._21_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__373_84  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._21_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__372_85  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._21_layer_._0_layer_norm_ReadVariableOp__366_86  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._21_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__369_87  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._21_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__367_88  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._21_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__370_89  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._21_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__368_90  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._20_layer_._1_layer_norm_ReadVariableOp__362_91  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._20_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__365_92  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._20_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__364_93  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._20_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__363_94  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._20_layer_._0_layer_norm_ReadVariableOp__357_95  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._20_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__360_96  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._20_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__358_97  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._20_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__361_98  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._20_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__359_99  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._2_layer_._1_layer_norm_ReadVariableOp__200_100  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._2_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__203_101  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._2_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__202_102  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._2_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__201_103  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._2_layer_._0_layer_norm_ReadVariableOp__195_104  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._2_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__198_105  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._2_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__196_106  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._2_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__199_107  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._2_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__197_108  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._19_layer_._1_layer_norm_ReadVariableOp__353_109  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._19_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__356_110  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._19_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__355_111  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._19_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__354_112  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._19_layer_._0_layer_norm_ReadVariableOp__348_113  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._19_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__351_114  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._19_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__349_115  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._19_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__352_116  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._19_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__350_117  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._18_layer_._1_layer_norm_ReadVariableOp__344_118  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._18_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__347_119  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._18_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__346_120  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._18_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__345_121  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._18_layer_._0_layer_norm_ReadVariableOp__339_122  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._18_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__342_123  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._18_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__340_124  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._18_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__343_125  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._18_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__341_126  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._17_layer_._1_layer_norm_ReadVariableOp__335_127  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._17_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__338_128  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._17_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__337_129  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._17_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__336_130  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._17_layer_._0_layer_norm_ReadVariableOp__330_131  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._17_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__333_132  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._17_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__331_133  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._17_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__334_134  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._17_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__332_135  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._16_layer_._1_layer_norm_ReadVariableOp__326_136  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._16_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__329_137  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._16_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__328_138  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._16_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__327_139  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._16_layer_._0_layer_norm_ReadVariableOp__321_140  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._16_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__324_141  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._16_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__322_142  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._16_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__325_143  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._16_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__323_144  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._15_layer_._1_layer_norm_ReadVariableOp__317_145  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._15_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__320_146  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._15_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__319_147  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._15_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__318_148  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._15_layer_._0_layer_norm_ReadVariableOp__312_149  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._15_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__315_150  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._15_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__313_151  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._15_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__316_152  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._15_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__314_153  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._14_layer_._1_layer_norm_ReadVariableOp__308_154  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._14_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__311_155  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._14_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__310_156  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._14_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__309_157  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._14_layer_._0_layer_norm_ReadVariableOp__303_158  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._14_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__306_159  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._14_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__304_160  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._14_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__307_161  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._14_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__305_162  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._13_layer_._1_layer_norm_ReadVariableOp__299_163  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._13_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__302_164  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._13_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__301_165  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._13_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__300_166  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._13_layer_._0_layer_norm_ReadVariableOp__294_167  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._13_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__297_168  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._13_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__295_169  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._13_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__298_170  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._13_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__296_171  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._12_layer_._1_layer_norm_ReadVariableOp__290_172  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._12_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__293_173  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._12_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__292_174  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._12_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__291_175  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._12_layer_._0_layer_norm_ReadVariableOp__285_176  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._12_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__288_177  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._12_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__286_178  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._12_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__289_179  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._12_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__287_180  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._11_layer_._1_layer_norm_ReadVariableOp__281_181  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._11_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__284_182  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._11_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__283_183  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._11_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__282_184  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._11_layer_._0_layer_norm_ReadVariableOp__276_185  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._11_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__279_186  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._11_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__277_187  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._11_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__280_188  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._11_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__278_189  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._10_layer_._1_layer_norm_ReadVariableOp__272_190  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._10_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__275_191  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._10_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__274_192  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._10_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__273_193  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._10_layer_._0_layer_norm_ReadVariableOp__267_194  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._10_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__270_195  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._10_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__268_196  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._10_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__271_197  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._10_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__269_198  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._1_layer_._1_layer_norm_ReadVariableOp__191_199  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._1_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__194_200  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._1_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__193_201  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._1_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__192_202  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._1_layer_._0_layer_norm_ReadVariableOp__186_203  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._1_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__189_204  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._1_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__187_205  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._1_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__190_206  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._1_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__188_207  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._0_layer_._1_layer_norm_ReadVariableOp__182_208  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._0_layer_._1_DenseReluDense_wo_Tensordot_ReadVariableOp__185_209  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._0_layer_._1_DenseReluDense_wi_1_Tensordot_ReadVariableOp__184_210  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._0_layer_._1_DenseReluDense_wi_0_Tensordot_ReadVariableOp__183_211  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._0_layer_._0_layer_norm_ReadVariableOp__177_212  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._0_layer_._0_SelfAttention_v_Tensordot_ReadVariableOp__180_213  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._0_layer_._0_SelfAttention_q_Tensordot_ReadVariableOp__178_214  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._0_layer_._0_SelfAttention_o_Tensordot_ReadVariableOp__181_215  \n",
      " extracting: StatefulPartitionedCall_tf_t5encoder_model_encoder_block_._0_layer_._0_SelfAttention_k_Tensordot_ReadVariableOp__179_216  \n",
      " extracting: Func_StatefulPartitionedCall_input__6__7_217  \n",
      " extracting: Func_StatefulPartitionedCall_input__1__6_218  \n"
     ]
    }
   ],
   "source": [
    "!mkdir -p cpm_2_0_encoder_onnx && cd cpm_2_0_encoder_onnx && unzip ../cpm_2_0_encoder_onnx.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
